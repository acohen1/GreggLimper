{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "intro",
      "source": [
        "# Milvus GPU on WSL2 \u2014 Verified Setup (Docker Compose)\n",
        "\n",
        "This runbook captures a clean setup of Milvus Standalone **with GPU acceleration** on Windows 11/WSL2 using Docker Desktop. It reflects the current Milvus documentation for GPU deployments and adds the extra checks needed to confirm that work actually lands on the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "prereqs",
      "source": [
        "## 1. Check the official GPU prerequisites\n",
        "\n",
        "Milvus requires specific NVIDIA hardware and drivers before you ever pull a container:\n",
        "\n",
        "- GPU compute capability must be 6.0, 7.0, 7.5, 8.0, 8.6, or 9.0. Use NVIDIA's tables to verify your card.\n",
        "- Install a recent NVIDIA driver (545+) on Windows and inside WSL, and add the **NVIDIA Container Toolkit** so Docker can forward the GPU into containers.\n",
        "- Validate the driver stack with `modinfo nvidia | grep \"^version\"` inside WSL \u2014 it should report the same version you installed.\n",
        "\n",
        "See the \"Requirements for Installing Milvus with GPU\" page for the full prerequisite checklist and driver guidance. Keep that page handy if you need to troubleshoot a driver mismatch later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "tip",
      "source": [
        ">\n",
        "**Tip:** On Windows, keep the standard GeForce/RTX driver current. Inside WSL2, use the Ubuntu packages that match that version (example below). If the versions diverge, GPU passthrough frequently fails."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "baseline",
      "source": [
        "## 2. Baseline the WSL2 environment\n",
        "\n",
        "From an elevated PowerShell session:\n",
        "\n",
        "```powershell\n",
        "wsl --status\n",
        "wsl -l -v\n",
        "```\n",
        "\n",
        "Then, in Ubuntu (WSL2):\n",
        "\n",
        "```bash\n",
        "# Kernel + systemd\n",
        "uname -r\n",
        "cat /proc/version\n",
        "systemctl is-system-running || true\n",
        "\n",
        "# Docker Desktop integration\n",
        "docker version\n",
        "docker info | head -n 20\n",
        "```\n",
        "\n",
        "If Docker is unreachable, open **Docker Desktop \u2192 Settings \u2192 Resources \u2192 WSL Integration** and enable your Ubuntu distro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "drivers",
      "source": [
        "## 3. Install/refresh NVIDIA packages inside WSL2\n",
        "\n",
        "The Milvus docs recommend installing the headless driver build plus the container toolkit on Ubuntu 22.04+.\n",
        "\n",
        "```bash\n",
        "sudo apt-get update\n",
        "sudo apt-get install --no-install-recommends -y   nvidia-headless-545 nvidia-utils-545   nvidia-container-toolkit\n",
        "\n",
        "# Verify that the driver and toolkit registered correctly\n",
        "modinfo nvidia | grep \"^version\"\n",
        "```\n",
        "\n",
        "If you use a different distribution, follow NVIDIA's official installation guide for the container toolkit and pick the matching driver package. After installation, restart WSL (`wsl --shutdown`) so the new kernel modules load."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cuda-check",
      "source": [
        "## 4. Confirm Docker sees the GPU\n",
        "\n",
        "Back in Ubuntu, run the CUDA base image to ensure `nvidia-smi` works inside containers:\n",
        "\n",
        "```bash\n",
        "docker run --rm --gpus all nvidia/cuda:12.5.1-base-ubuntu24.04 nvidia-smi\n",
        "```\n",
        "\n",
        "You should see your GPU(s) listed with the correct driver version. If this fails, revisit the driver and container toolkit setup before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "compose",
      "source": [
        "## 5. Download the official GPU docker-compose file\n",
        "\n",
        "Create a workspace and pull the compose file published with the Milvus release you are targeting:\n",
        "\n",
        "```bash\n",
        "mkdir -p ~/milvus && cd ~/milvus\n",
        "wget https://github.com/milvus-io/milvus/releases/download/v2.6.5/milvus-standalone-docker-compose-gpu.yml -O docker-compose.yml\n",
        "```\n",
        "\n",
        "Edit `docker-compose.yml` so the `standalone` service reserves the GPU IDs you want Milvus to use:\n",
        "\n",
        "```yaml\n",
        "standalone:\n",
        "  ...\n",
        "  deploy:\n",
        "    resources:\n",
        "      reservations:\n",
        "        devices:\n",
        "          - driver: nvidia\n",
        "            capabilities: [\"gpu\"]\n",
        "            device_ids: [\"0\"]        # one GPU\n",
        "```\n",
        "\n",
        "Milvus supports multiple GPUs; list them as `device_ids: [\"0\", \"1\"]` if you want to expose two cards. This mirrors the guidance in the Milvus GPU installation manual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "cuda-visible",
      "source": [
        ">\n",
        "**Optional:** If you need to further constrain GPU visibility at runtime, wrap the start command with `CUDA_VISIBLE_DEVICES=0` (or similar) \u2014 the official docs note this as the supported override."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "launch",
      "source": [
        "## 6. Launch Milvus with GPU support\n",
        "\n",
        "From the same directory:\n",
        "\n",
        "```bash\n",
        "docker compose up -d\n",
        "docker compose ps\n",
        "docker logs -f milvus-standalone\n",
        "```\n",
        "\n",
        "You should see `milvus-etcd`, `milvus-minio`, and `milvus-standalone` in the **Up** state. Keep the logs open until Milvus reports it has started services; seeing only `tini` means the wrong image was pulled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "verify",
      "source": [
        "## 7. Verify the GPU inside the Milvus container\n",
        "\n",
        "Check that the Milvus container has access to the GPU device:\n",
        "\n",
        "```bash\n",
        "docker compose exec milvus-standalone nvidia-smi\n",
        "```\n",
        "\n",
        "The GPUs should appear under `GPU` with matching driver/runtime versions. If the `Processes` table is empty, that's expected while Milvus is idle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "workload",
      "source": [
        "## 8. Drive an actual GPU workload (Python quick test)\n",
        "\n",
        "Milvus only touches the GPU while building or querying GPU-backed indexes (for example `GPU_CAGRA`, `GPU_IVF_FLAT`, `GPU_IVF_PQ`, or `GPU_BRUTE_FORCE`). Use the snippet below to create a collection, insert data, build a `GPU_CAGRA` index, and run a search. The index build/search phases will momentarily show up in `nvidia-smi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "id": "code",
      "outputs": [],
      "source": [
        "%%bash\n",
        "python - <<'PY'\n",
        "from pymilvus import (\n",
        "    connections,\n",
        "    FieldSchema, CollectionSchema, DataType,\n",
        "    Collection\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Connect to the standalone Milvus instance\n",
        "connections.connect(host=\"127.0.0.1\", port=\"19530\")\n",
        "\n",
        "# Drop any leftover collection from previous runs\n",
        "COLLECTION_NAME = \"gpu_quickstart\"\n",
        "if COLLECTION_NAME in [c.name for c in Collection.list_collections()]:\n",
        "    Collection(COLLECTION_NAME).drop()\n",
        "\n",
        "# Define schema\n",
        "fields = [\n",
        "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
        "    FieldSchema(name=\"emb\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
        "]\n",
        "schema = CollectionSchema(fields, description=\"GPU validation demo\")\n",
        "\n",
        "# Create collection and insert random vectors\n",
        "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
        "np.random.seed(42)\n",
        "N = 20000\n",
        "ids = np.arange(N)\n",
        "embeddings = np.random.random((N, 384)).astype(np.float32)\n",
        "collection.insert([ids, embeddings])\n",
        "\n",
        "# Build a GPU index (GPU_CAGRA) and load it\n",
        "collection.create_index(\n",
        "    field_name=\"emb\",\n",
        "    index_params={\n",
        "        \"index_type\": \"GPU_CAGRA\",\n",
        "        \"metric_type\": \"L2\",\n",
        "        \"params\": {\"graph_degree\": 32}\n",
        "    }\n",
        ")\n",
        "collection.load()\n",
        "\n",
        "# Run a search to exercise the GPU\n",
        "search_vec = embeddings[:5]\n",
        "results = collection.search(\n",
        "    search_vec,\n",
        "    \"emb\",\n",
        "    param={\"metric_type\": \"L2\", \"search_width\": 8},\n",
        "    limit=5,\n",
        ")\n",
        "print(f\"Search completed, hits for first query: {[hit.id for hit in results[0]]}\")\n",
        "\n",
        "# Clean up so the next run starts fresh\n",
        "collection.drop()\n",
        "PY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "watch",
      "source": [
        "While the index builds or searches run, execute `watch -n 1 nvidia-smi` in another terminal \u2014 Milvus should briefly appear in the process list with GPU memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "tuning",
      "source": [
        "## 9. Optional tuning (memory pool)\n",
        "\n",
        "If you need to adjust GPU memory reservations, copy `/milvus/configs/milvus.yaml` out of the container, edit the `gpu.initMemSize` and `gpu.maxMemSize` values, then copy the file back and restart the container. This mirrors the memory-pool guidance in the Milvus GPU install manual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "shutdown",
      "source": [
        "## 10. Shutdown / restart\n",
        "\n",
        "When finished:\n",
        "\n",
        "```bash\n",
        "docker compose down\n",
        "```\n",
        "\n",
        "To reboot later, re-open Ubuntu, `cd ~/milvus`, and run `docker compose up -d` again. Verify with `docker compose ps` before reconnecting from Python."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}